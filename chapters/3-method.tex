\chapter{Methodology} \label{chap:method}
In Chapter \ref{chap:method}, the overall research design, methodology, and implementation for this thesis will be described. Section \ref{sec:motivation} describes the motivation behind this research, followed by the research questions in Section \ref{sec:questions}. Subsequently, Section \ref{sec:method} describes the research methodology and design. Finally, Section \ref{sec:implementation} presents the implementation of the research.

\section{Research Motivation} \label{sec:motivation}
When an organization discovers a security vulnerability in its deployed web application, it needs to address that vulnerability as quickly and as thoroughly as possible to prevent bad actors from potentially wreaking havoc. The most obvious resolution strategy is for the organization to identify the vulnerable source code, fix the vulnerable source code, and then deploy and install a patch containing that fix. However, this strategy may not always be possible or timely. OWASP \cite{virtualpatchingbest} \cite{virtualpatchingcheat} gives several reasons for this:

\begin{itemize}
\item Third party software - If the vulnerability is caused by or lies within a vendor's commercial module or application, then the organization, as a customer, may not have access to the relevant source code. The organization has to wait for the vendor's official patch, which may not be available as quickly as the customer would like.

\item Long installation time - Even if a patch is quickly and readily available, extensive and time-consuming regression testing is often needed prior to deployment into production.

\item Lack of resources - Developers may already be allocated to other projects, and/or it may be deemed too expensive to fix the custom code causing the vulnerability.

\item Legacy Code - The organization may be necessarily utilizing a commercial application or module that is no longer actively supported by the vendor.

\item Outsourced Code - The organization may be outsourcing some or all of their application development, adding an additional layer of complexity. Asking for a vulnerability fix may require an entirely new project and additional cost.
\end{itemize}



Intrusion Protection Systems and Web Application Firewalls can mitigate these issues, often completely, in strategy known as virtual patching. OWASP's Virtual Patching Cheat Sheet \cite{virtualpatchingcheat} provides the following the following definition for virtual patching:
"A security policy enforcement layer which prevents and reports the exploitation attempt of a known vulnerability". 
Unlike typical WAF strategies, which see the firewall deployed site-wide with little regard to the specific structure of the underlying application, virtual patching is meant to apply only to certain resources and parameters, resulting in rules and signatures that are specific to the  application under protection. 

As with WAFs in general, virtual patching can use a positive security (whitelist) or negative security (blacklist) model. 

In order to create whitelist virtual patches, it must be known what the valid and expected input values are for a given parameter or resource. This is generally the recommended strategy \cite{virtualpatchingcheat}, especially since it can be applied to every parameter and resource in the web application regardless of the existence of vulnerabilities. This can be considered a form of defense-in-depth (CITATION NEEDED). 

Although there have been attempts to automate whitelist virtual patching, it remains a largely manual process. Betarte et al. \cite{betarte_towards_2016} developed a tool called DEPSA that could translate "security requirements expressed in a high-level language over a model of the vulnerable application" into both whitelist and virtual patches (specifically, ModSecurity rules). However, the application needs to be modeled and the requirements specified, both of which are largely manual processes.

For blacklist virtual patches, the goal is to create rules that block the specific types of attacks that can exploit the underlying application's vulnerabilities. However, one must take care not to create an exploit patch that is too specific, e.g., a patch that only blocks a specific payload, since these types of rules can be easily bypassed by a dedicated attacker. [EXAMPLE HERE]

Automated blacklist virtual patch creation seems to have more tools, however most are proprietary commercial solutions that rely on the output of a proprietary DAST, and some of those are a decade old and are likely obsolete. None have been independently assessed or evaluated in academic literature. The OWASP ModSecurity Core Rule Set has virtual patching scripts that parse vulnerability reports generated by open-source DASTs such as OWASP ZAP and Arachni Web Scanner, but they are also a decade old and no longer function as originally intended, and have not been rigorously evaluated. There is a blog post by a computer security company that describes in-depth an approach to blacklist virtual patching via static analysis, but this has not been evaluated by or referenced in academic literature.

In terms of related academic works to automated blacklist virtual patching, there is the aforementioned DEPSA \cite{betarte_towards_2016}, but the limitation mentioned in the whitelisting discussion above also seems to apply for blacklist rule creation. Salemi et al. \cite{waf_rasp}. explores automatically generating WAF rules via Runtime Application Self Protection (RASP) logs. However, the WAF is intentionally redundant in this approach since RASPs already detect and block malicious requests.

Finally, according to OWASP \cite{virtualpatchingcheat} there are two main tenants with regards to virtual patching, where order indicates priority:
\begin{enumerate}
\item No false positives - Do not block benign traffic.
\item No false negatives - Do not allow attacks.
\end{enumerate}

To see why the first tenant should have precedence over the second, consider the adverse effects false positives can have on an organization's business. If users and customers are often unable to complete transactions due to their legitimate requests being blocked, they will become frustrated and as a result the organization may have some unhappy customers, potentially leading to loss of business and thus revenue. To assuage this, the organization might configure the WAF to operate in a detection-only mode, but this only serves to undermine the second tenant since attacks can no longer be proactively blocked.

Given the lack of open-source implementations and academic study of automated virtual patching, this research aims to investigate the feasibility and effectiveness of such solutions relative to a standard, site-wide set of rules. The ranked tenants above will serve as guidelines for what to implement and evaluate.


\section{Research Questions} \label{sec:questions}
The research motivation described in \ref{sec:motivation} yielded three research questions. They are as follows:
\begin{enumerate}
	\item How can dynamic analysis be used to automatically generate virtual patches for a vulnerable application?
	\item How can static analysis be used to automatically generate virtual patches for a vulnerable application?
	\item How effective are automatically generated virtual patches compared to a standard set of WAF rules?
\end{enumerate}

\section{Research Method and Design} \label{sec:method}
This section will describe the overall research method and design for this thesis. This includes the research strategy, data generation and analysis methods, and the underlying research paradigm.

\subsection{Research Strategy} \label{subsec:strategy}
To address the research questions, a prototypical tool called the Virtual Patchinator will be developed and evaluated. This tool will process the reports generated by dynamic and static analysis tools for a vulnerable application and generate virtual patches. This strategy can be considered an experimental strategy \cite{oates2005researching}, since it will be characterized by the observation, measurement, and comparison of results obtained with and without the implemented prototype.


\subsection{Data Generation and Analysis}\label{subsec:data}
Data generation will consist of the results of attacking various vulnerable web applications with and without a web application firewall. When the applications under attack are behind a web application firewall, different rule sets corresponding to the virtual patches generated by the Virtual Patchinator will be used in addition to a standard, site-wide set of rules. The input vectors for the attacks will come from FuzzDB datasets as well as the dynamic analysis tools used to generate the patches. The number of true/false negatives will be counted. In order to collect results for true/false positives, a benign dataset consisting of words from free e-books will be used. 

\subsection{Research Paradigm}\label{subsec:paradigm}




\section{Research Implementation} \label{sec:implementation}